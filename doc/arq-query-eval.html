<!--<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">-->
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
    <title>ARQ - Extending Query Execution</title>
    <link href="Styles/doc.css" rel="stylesheet" type="text/css" />
</head>
<body>
    <h1>ARQ - Extending Query Execution</h1>
    <p>
        This page describes several mechanisms that can be used to extend the ARQ query engine. 
        Through these mechanisms, ARQ can be used to query different graph and a dataset 
        implementation and also to provide different query evaluation and optimization 
        strategies for particular circumstances.&nbsp; These
        mechanisms are used by <a href="http://jena.sf.net.SDB">SDB</a> and <a href="http://jena.sf.net/TDB">
            TDB</a>.</p>
    <p>
        These mechanisms are not the way to add specific custom operations that do not 
        need change how a query is evaluated.
        ARQ can be <a href="extension.html">extended in various ways</a>. <a href="extension.html#valueFunctions">
            Custom filter functions</a> and <a href="extension.html#propertyFunctions">property
                functions</a> provide ways to add application specific code. The <a href="lucene-arq.html">
                    free text search</a> capabilities, using Apache Lucene, are provided via a
        property function. Custom filter functions and property functions should be used where possible.</p>
    <p>
        Applications writers who extend ARQ at the query execution level should be prepared
        to work with the source code for ARQ for specific details and for finding code to
        reuse.</p>
    <ul>
      <li><a href="#Overview">Overview of ARQ Query Processing</a></li>
      <li><a href="#mainQueryEngine">The Main Query Engine</a></li>
      <li><a href="#stageGenerator">Graph matching and a custom StageGenerator</a></li>
      <li><a href="#OpExecutor">OpExecutor</a></li>
      <li><a href="#quads">Quads</a></li>
      <li><a href="#mixedDatasets">Mixed Graph Implementation Datasets</a></li>
      <li><a href="#CustomQueryEngines">Custom Query Engines</a></li>
      <li><a href="#AlgebraExtensions">Extend the algebra</a></li>
    </ul>
    
    <h2 id="Overview">Overview of ARQ Query Processing</h2>
    <p>
        The sequence of actions performed by ARQ to perform a query are parsing, algebra
        generation, execution building, high-level optimization, low level optimization and finally 
        evaluation. It is not usual to modify the parsing and algebra generation steps. 
        Extensions are provided transforming the algebra form. See also the 
        documentation on <a href="algebra.html">working with the SPARQL algebra in ARQ</a> 
        including building algebra expressions programmatically, rather than obtaining 
        them from a query string.</p>
    <h3>
                Parsing</h3>
    <p>
        Turns a query string into a Query object. The class Query is abstract syntax tree (AST) for the query and provides methods to create a query, primarily for the parser. The Query object also provides methods to serialize the query 
        to a string. Because this is the AST, the string produced is very close to the original query with the same syntactic elements but no comments and formatted with a whitespace for readability. It is not usually the best way to build a query programmatically and the AST is not normally an extension point. 
        </p>
    
    <p>
        The Query object can be used many times. It is not modified once created, and in
        particular it is not modified by query execution.
    </p>
    <h3>
        Algebra generation</h3>
    <p>
        ARQ generates the <a href="http://www.w3.org/TR/rdf-sparql-query/#sparqlQuery">
        SPARQL algebra</a> expression for the query. After this a number of 
        transformations can be applied (for example, identification of property 
        functions) but the first step is the application of the algorithm in the SPARQL 
        specification for translating a SPARQL query string, as held in a <code>Query</code> 
        object into a SPARQL algebra expression. This includes the process of removing 
        joins involving the identity pattern (the empty graph pattern).</p>
    <p>
        For example, the query:</p>
    <pre class="box">PREFIX foaf: &lt;http://xmlns.com/foaf/0.1/&gt;
SELECT ?name ?mbox ?nick
WHERE  { ?x foaf:name  ?name ;
            foaf:mbox  ?mbox .
         OPTIONAL { ?x  foaf:nick  ?nick }
       }</pre>
    <p>becomes</p>
    <pre class="box">
(prefix ((foaf: &lt;http://xmlns.com/foaf/0.1/&gt;))
  (project (?name ?mbox ?nick)
    (leftjoin
      (bgp
        (triple ?x foaf:name ?name)
        (triple ?x foaf:mbox ?mbox)
      )
      (bgp (triple ?x foaf:nick ?nick)
      )
    )))</pre>
    <p>using the <a href="http://jena.hpl.hp.com/wiki/SSE">SSE syntax</a> to write out 
        the internal datastructure for the algebra.</p>
    <p>The <a href="http://www.sparql.org/validator.html">online SPARQL validator</a> at
        <a href="http://sparql.org/">sparql.org</a> 
        can be used to see the algebra expression for a SPARQL query.</p>
    <h3>
        High-Level Optimization</h3>
    <p>
        There is a collection of transformations that can be applied to the algebra such 
        as replacing equality filters with a more efficient graph pattern and an 
        assignment. When extending ARQ, a query processor for a custom storage lay can 
        choose which optimizations are appropriate and can also provide its own algebra 
        transformations.</p>
    <p class="todo">
        @@Transformations</p>
    <h3>
        Low-Level Optimization</h3>
    <p>
        Low level optimizations include choosing the order in which to evaluate basic 
        graph patterns. These are the responsibility of the custom storage layer.</p>
    <h3>
        Evaluation</h3>
    <p>
        The step of evaluating a query is the process of executing the algebra 
        expression, as modified by any transformations applied to yield a stream of 
        pattern solutions.</p>
    <p>
        Low-level optimization is usually carried out as part of evaluation.</p>
    <p class="todo">
        @@Iterators</p>
    <h3>
        QueryExecutionFactory and QueryEngineFactory</h3>
    <p>
        The steps from algebra generation to query evaluation are carried out when a 
        query is executed via the <code>QueryExecution.execSelect</code> or other <code>
        QueryExecution</code> exec 
        operation. It is possible to carry out storage-specific operations when the 
        query execution is created.</p>
    <p>
        The QueryExecutionFactory provides many convenience operations. If a Model is 
        provided for the data, it is incorporated into an RDF dataset that has that 
        model for the default graph.</p>
    <p>
        ARQ provides three query engine factories; the main query engine factory, one 
        for a reference query engine and one to remotely execute a query. SDB and TDB 
        provide their own query engine factories which they register during 
        sub-system initialization. Both extend the main query engine described 
        below.</p>
    <p>
        The reference query engine is a direct top-down evaluation of the expression. It's purpose
        is to be simple so it can be easily verified and checked then its results used to
        check more complicated processing in the main engine and other implementations.
        All arguments to each operator are fully evaluated, to produce intermediate, in-memory
        tables, then the operators called to calculate it's results. It does not scale and
        does not perform any optimizations. It is intended to be clear and simple; it is 
        not designed to be efficient.
    </p>
    <p>
        Query engines are chosen by referring to the registry of query engine factories.</p>
    <pre class="box">public interface QueryEngineFactory
{
    public boolean accept(Query query, DatasetGraph dataset, Context context) ;
    public Plan create(Query query, DatasetGraph dataset, Binding inputBinding, Context context) ;
    
    public boolean accept(Op op, DatasetGraph dataset, Context context) ;
    public Plan create(Op op, DatasetGraph dataset, Binding inputBinding, Context context) ;
}</pre>
    <p>
        When the query execution factory is given a dataset and query, the query 
        execution factory tries each registered engine factory in turn calling the <code>
        accept</code> method (for query of algebra depending on how it was presented). The registry is 
        kept in reverse registration order - the most recently registered query engine 
        factory is tried first. The first query engine factor to return true is chosen 
        and no further engine factories are checked.</p>
    <p>
        When a query engine factory is chosen, the <code>create</code> method is called 
        to return a <code>Plan</code> object for the execution. The main 
        operation of the plan interface is to get the <code>QueryIterator</code> 
        for the query.</p>
    <p>
        &nbsp;See the example in <code>src-examples/arq.examples.engine.MyQueryEngine</code> 
        (examples are to be found in the ARQ download).</p>

        
    <h2 id="mainQueryEngine">The Main Query Engine</h2>
    <p>The main query engine can execute any query. It contains a number of 
    basic graph pattern matching implementations including one that uses the
    <code>Graph.find</code> operation so it can work with any implementation of 
    the Jena Graph SPI. The main query engine works with general purpose 
    datasets but not quad stores directly; it evaluates patterns on each graph 
    in turn.</p>
    <p>The main query engine includes the optimization for the standard Jena 
    implementation of in-memory graphs.</p>
    <p>ARQ does provide a algebra transform to turn a SPARQL algebra expression 
    involving named graphs and triples into one using quads. See <code>
    Alegebra.toQuadForm</code>.</p>
    <p>High-level optimization is performed by a sequence of transformation. 
    This set of optimizations is evolving. A custom implementation of a query 
    engine can reuse some or all of these transformations (see <code>
    Algebra.optimize</code> which is the set of transforms used by the main 
    query engine).</p>
    <p>The main query engine is a streaming engine. It evaluates expressions as 
    the client consumes each query solution. </p>
     <p>After preparing the execution by creating the initial conditions (a 
    partial solution of one row and no bound variables or any initial bindings 
    of variables), the main query engine calls QC.execute which is the algorithm 
    to execute a query. Any extension that wished to reuse some of the main 
    query engine by providing it's own <code>OpExecutor</code> must call this 
    method to evaluate a sub-operation.</p>
    <p><code>QC.execute</code> finds the currently active <code>OpExecutor</code> 
    factory, creates an <code>OpExecutor</code> object and invokes it to 
    evaluate one algebra operation.</p>
    <p>There are two points of extension for the main query engine:</p>
    <ul>
      <li>Stage Generators, for evaluating basic graph patterns and reusing the 
      rest of the engine.</li>
      <li><code>OpExecutor</code> to execute any algebra operator specially.</li>
    </ul>
    <p>The standard <code>OpExecutor</code> invokes the stage generator 
    mechanism to match a basic graph pattern.</p>
    
    <h2 id="stageGenerator">Graph matching and a custom StageGenerator</h2>
    <p>
        The correct point to hook into ARQ for just extending basic graph 
        pattern matching (BGPs) is to provide a custom
        <code>StageGenerator</code>.&nbsp; (To hook into filtered basic graph 
        patterns, the extension will need to provide it's own <code>OpExecutor</code> 
        factory).
        The advantage of the <code>StageGenerator</code> mechanism, as compared 
        to the more general <code>OpExecutor</code> described below, is that it 
        more self-contained and requires less detail about the internal 
        evaluation of the other SPARQL algebra operators.&nbsp; This extension 
        point corresponds to section 12.6 &quot;<a href="http://www.w3.org/TR/rdf-sparql-query/#sparqlBGPExtend">Extending 
        SPARQL Basic Graph Matching</a>&quot;.</p>
    <p>
        Below is the default code to match a BGP in <code>
        OpExecutor.execute(OpBGP, QueryIterator)</code>. The input is a stream 
        of results from earlier stages. The execution must return a query 
        iterator that is all the possible ways to match the basic graph pattern 
        for each of the inputs in turn. Order of results does not matter.&nbsp;
    </p>
    <pre class="box">protected QueryIterator execute(OpBGP opBGP, QueryIterator input)
{
    BasicPattern pattern = opBGP.getPattern() ;
    return StageBuilder.execute(pattern, input, execCxt) ;
}</pre>
    <p>The
        <code>StageBuilder</code> looks for the stage generator by accessing the 
    context for the execution:</p>
<pre class="box">        (StageGenerator)context.get(ARQ.stageGenerator) ;</pre>
    <p>where the context is the global context and any query execution specific 
    additions.</p>
    <p>A <code>StageGenerator</code> is an implementation of:</p>
    
    <pre class="box">
    public interface StageGenerator
    {
        public QueryIterator execute(BasicPattern pattern, 
                                     QueryIterator input,
                                     ExecutionContext execCxt) ;
    }
</pre>
    
    <h3>Setting the Stage Generator</h3>
    <p>An extension stage generator can be registered on a per-query execution 
    basis or (more usually) in the global context.</p>
    <pre class="box">
    StageBuilder.setGenerator(Context, StageGenerator)    </pre>
    <p>The global context can be obtained by a call to <code>ARQ.getContext()</code></p>
    <pre class="box">    StageBuilder.setGenerator(<code>ARQ.getContext()</code>, myStageGenerator) ;</pre>
    <p>In order to allow an extensions to still permit other graphs to be used, 
    stage generators are usually chained, with each new custom one passing the 
    execution request up the chain if the request is not supported by this 
    custom stage generator.</p>
    <pre class="box">public class MyStageGenerator implements StageGenerator
{
    StageGenerator above = null ;
    
    public MyStageGenerator (StageGenerator original)
    { above = original ; }
    
    @Override
    public QueryIterator execute(BasicPattern pattern, QueryIterator input, ExecutionContext execCxt)
    {
        Graph g = execCxt.getActiveGraph() ;
        // Test to see if this is a graph we support.  
        if ( ! ( g instanceof MySpecialGraphClass ) )
            // Not us - bounce up the StageGenerator chain
            return above.execute(pattern, input, execCxt) ;
        MySpecialGraphClass graph = (MySpecialGraphClass )g ;
        // Create a QueryIterator for this request
     ... 
  </pre>
    <p>This is registered by setting the global context (<code>StageBuilder</code> 
    has a convenience operation to do this):</p>
    
    <pre class="box">
  // Get the standard one. 
  StageGenerator orig = (StageGenerator)ARQ.getContext().get(ARQ.stageGenerator) ;
  // Create a new one 
  StageGenerator myStageGenerator= new MyStageGenerator(orig) ;
  // Register it
  StageBuilder.setGenerator(<code>ARQ.getContext()</code>, myStageGenerator) ;
   </pre>

    <h2 id="OpExecutor">OpExecutor</h2>

  <p>A <code>StageGenerator</code> provides matching for a basic graph pattern. If an extension wishes to take
  responsibility for more of the evaluation then it needs to work with <code>OpExecutor</code>.
  This includes evaluation of filtered basic graph patterns.</p>
    <p>An example query using a filter:</p>
    <pre class="box">PREFIX  dc:   &lt;http://purl.org/dc/elements/1.1/&gt;
PREFIX  books: &lt;http://example.org/book/&gt;

SELECT  *
WHERE
  { ?book  dc:title  ?title .
    FILTER regex(?title, &quot;Paddington&quot;)
  }</pre>
    <p>&nbsp;results in the algebra expression for the pattern:</p>
    <pre class="box">    (filter (regex ?title &quot;Paddington&quot;)
        (bgp (triple ?book dc:title ?title)
        ))</pre>
    <p>showing that the filter is being applied to the results of a basic graph 
    pattern matching.</p>
    <p>This is not the way to provide custom filter operations.&nbsp; See the 
    documentation for <a href="extension.html#valueFunctions">
    application-provided filter functions</a>. </p>
    <p>Each step of evaluation in the main query engine is performed by a 
    <code>OpExecutor</code> and a new one is created at from a factory at each step.&nbsp; 
    The factory is registered in the execution's context. The implementation of 
    a specialized <code>OpExecutor</code> can inherit from the standard one and 
    override only those algebra operators it wishes to deal with, including inspecting the execution and choosing to passing up to the superclass based 
    on the details of the operation.&nbsp; From the query above, only regex 
    filters might be specially handled.</p>
    <p>Registering an <code>OpExecutorFactory</code>:</p>
    <pre class="box">OpExecutorFactory customExecutorFactory = new MyOpExecutorFactory(...) ;
QC.setFactory(ARQ.getCOntext(), customExecutorFactory) ;</pre>
    <p>QC is a point of indirection that chooses the execution process at each 
    stage in a query so if the custom execution wishes to evaluate an algebra 
    operation within another operation, is can call <code>QC.execute</code>. Be 
    careful not to loop endlessly of the operation is itself handled by the 
    custom evaluator. This can be done by swapping in a different OpExecutorFactory.</p>
    <pre class="box">   // Execute an operation with a different OpExecution Factory

   // New context.
   ExecutionContext ec2 = new ExecutionContext(execCxt) ;
   ec2.setExecutor(plainFactory) ;

   QueryIterator qIter = QC.execute(op, input, ec2) ;</pre>
    <pre class="box">   private static OpExecutorFactory plainFactory = new OpExecutorPlainFactory() ;
   private static class OpExecutorPlainFactory implements OpExecutorFactory
   {
       @Override
       public OpExecutor create(ExecutionContext execCxt)
       {
           return new OpExecutor(execCxt) ;		// The default OpExecutor of ARQ.
       }
  }</pre>

    <h2 id="quads">Quads</h2>
    <p>If a custom extension provides named graphs, then it may be useful to 
    execute the quad form of the query. This is done by writing a custom query 
    engine and overriding <code>QueryEngineMain.modifyOp</code>: </p>
    <pre class="box">  @Override
  protected Op modifyOp(Op op)
  { 
     op = Substitute.substitute(op, initialInput) ;	// Cope with initial bindings.
     op = super.modifyOp(op) ;			// Use standard optimizations.
     op = Algebra.toQuadForm(op) ;			// Turn into quad form.
     return op ;
  }</pre>
    <p>The extension may need to provide its own dataset implementation so that 
    it can detect when queries are directed to its named graph storage.
    <a href="http://jena.sf.net/SDB">SDB</a> and
    <a href="http://jena.sf.net/TDB">TDB</a> are examples of this.</p>
    
    <h2 id="mixedDatasets"> Mixed Graph Implementation Datasets</h2>
    <p>The dataset implementation used in normal operation does not work on 
    quads but instead can provide a dataset with a collection of graphs each 
    from different implementation sub-systems. In-memory graphs can be mixed 
    with database backed graphs as well as custom storage systems. Query 
    execution proceeds per-graph so that an custom <code>OpExecutor</code> will 
    need to test the graph to work with to make sure it is of the right class. 
    The pattern in the <code>StageGenerator</code> extension point is an example 
    of design pattern in that situation.</p>

    
    <h2 id="CustomQueryEngines">Custom Query Engines</h2>
    <p>A custom query engine enables an extension to choose which datasets it 
    wishes to handle. It also allows the extension to intercept query execution 
    during the setup of the execution so it can modify the algebra expression, 
    introduce it's own algebra extensions, choose which high-level optimizations 
    to apply and also transform to the expression into quad form. Execution can 
    proceed with the normal algorithm or a custom <code>OpExecutor</code> or a 
    custom Stage Generator or a combination of all three extension mechanism.</p>
    <p>Only a small, skeleton custom query engine is needed to intercept the 
    initial setup. See the example in <code>src-examples/arq.examples.engine.MyQueryEngine</code>.</p>
    <p>While it 
    is possible to replace the entire process of query evaluation, this is a 
    substantial endeavour. <code>QueryExecutionBase</code> provides the 
    machinery for result presentation (SELECT, CONSTRUCT, DESCRIBE, ASK), 
    leaving the work of pattern evaluation to the custom query engine. <code>
    QueryExecutionFactory</code> assumes that <code>QueryExecutionBase</code> 
    will be used.</p>
    <h2 id="AlgebraExtensions">Algebra Extensions</h2>
    <p>New operators can be added to the algebra using the <code>OpExt</code> 
    class as the super-class of the new operator. They can be inserted into the 
    expression to be evaluated using a custom query engine to intercept 
    evaluation initialization.&nbsp; When evaluation of a query requires the 
    evaluation of a sub-class of <code>OpExt</code>, the <code>eval</code> 
    method is called. SDB uses this to introduce an operator that is implemented 
    in SQL.</p>
    
  <p class="footnote"><a href="documentation.html">ARQ Documentation Page</a></p>
    
</body>
</html>
